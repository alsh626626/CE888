{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1_Project2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNfl/o9pILHI1Jqq0/5nI1k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alsh626626/CE888/blob/main/Assignment/Assignment1_Project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TN3IBGn3-mj3",
        "outputId": "7e2db9cd-da7c-46bc-8570-3eee86f40040"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.3.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRIbfwMj827L"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification\r\n",
        "from transformers import TFAutoModelForSequenceClassification\r\n",
        "from transformers import AutoTokenizer\r\n",
        "import numpy as np\r\n",
        "from scipy.special import softmax\r\n",
        "import csv\r\n",
        "import urllib.request"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-l3UDpT-Tjr"
      },
      "source": [
        "# Preprocess text (username and link placeholders)\r\n",
        "def preprocess(text):\r\n",
        "    new_text = [\r\n",
        "    ]\r\n",
        "    for t in text.split(\" \"):\r\n",
        "        t = '@user' if t.startswith('@') and len(t) > 1 else t\r\n",
        "        t = 'http' if t.startswith('http') else t\r\n",
        "        new_text.append(t)\r\n",
        "    return \" \".join(new_text)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIVm7qW3_L5A"
      },
      "source": [
        "# Tasks:\r\n",
        "# emoji, emotion, hate, irony, offensive, sentiment\r\n",
        "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\r\n",
        "\r\n",
        "task='irony'\r\n",
        "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\r\n",
        "\r\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkq9LwyR_Ulg"
      },
      "source": [
        "# download label mapping\r\n",
        "labels=[]\r\n",
        "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\r\n",
        "with urllib.request.urlopen(mapping_link) as f:\r\n",
        "    html = f.read().decode('utf-8').split(\"\\n\")\r\n",
        "    csvreader = csv.reader(html, delimiter='\\t')\r\n",
        "labels = [row[1] for row in csvreader if len(row) > 1]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egI5ru4O_WQ4"
      },
      "source": [
        "# PT\r\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\r\n",
        "# model.save_pretrained(MODEL)\r\n",
        "\r\n",
        "text = \"Great, it broke the first day...\"\r\n",
        "text = preprocess(text)\r\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\r\n",
        "output = model(**encoded_input)\r\n",
        "scores = output[0][0].detach().numpy()\r\n",
        "scores = softmax(scores)\r\n",
        "\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvdIsI6C_e2P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16fd1f1e-cd9e-44e7-cfc6-71876d4d10dc"
      },
      "source": [
        "ranking = np.argsort(scores)\r\n",
        "ranking = ranking[::-1]\r\n",
        "for i in range(scores.shape[0]):\r\n",
        "    l = labels[ranking[i]]\r\n",
        "    s = scores[ranking[i]]\r\n",
        "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1) irony 0.914\n",
            "2) non_irony 0.086\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}